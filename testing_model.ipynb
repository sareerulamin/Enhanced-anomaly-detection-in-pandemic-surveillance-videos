{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5797af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import random\n",
    "from IPython.display import Image\n",
    "import imutils   \n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix, classification_report\n",
    "\n",
    "import keras\n",
    "import tensorflow.keras as K\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator, array_to_img, img_to_array\n",
    "from tensorflow.keras.applications import EfficientNetB1\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import imutils    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98525ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\"saved_cbam_eff0_model\")\n",
    "print(\"model has been loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a468c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a735e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "reconstructed_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ec129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 16\n",
    "epochs = 100\n",
    "num_classes = 8\n",
    "num_of_test_samples =4260 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6976de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(validation_split=0.3)\n",
    "\n",
    "train_generator = datagen.flow_from_directory('dataset', batch_size=batch_size, target_size=(224, 224), subset='training')\n",
    "validation_generator = datagen.flow_from_directory('dataset', batch_size=batch_size, target_size=(224, 224), shuffle=False, subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ee066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make prediction\n",
    "yhat_test = np.argmax(reconstructed_model.predict(validation_generator), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ae6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b66d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d17bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "batch_size=batch_size\n",
    "\n",
    "num_of_test_samples = 4260 \n",
    "target_names = [\"Coughing\",\"Face_Mask\",\"No_mask\",\"Nose_picking\",\"sneezing\",\"spitting\",\"wrong_mask\",\"yawn\"] \n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = reconstructed_model.predict_generator(validation_generator, num_of_test_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "#print('Confusion Matrix')\n",
    "cm = confusion_matrix(validation_generator.classes, y_pred)\n",
    "#print(cm)\n",
    "print('Classification Report')\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n",
    "# Normalise\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)\n",
    "fig, ax = plt.subplots(figsize=(20,7))\n",
    "\n",
    "sns.heatmap(cmn, center=0, annot=True, fmt='.2f', linewidths=1,  xticklabels=target_names, yticklabels=target_names)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show(block=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a1c4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_layer = next(x for x in reconstructed_model.layers[::-1] if isinstance(x, K.layers.Conv2D))\n",
    "last_conv_layer.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab84e993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/gkeechin/vizgradcam/blob/main/gradcam.py\n",
    "\n",
    "def VizGradCAM(model, image, interpolant=0.5, plot_results=True):\n",
    "\n",
    "    \"\"\"VizGradCAM - Displays GradCAM based on Keras / TensorFlow models\n",
    "    using the gradients from the last convolutional layer. This function\n",
    "    should work with all Keras Application listed here:\n",
    "    https://keras.io/api/applications/\n",
    "    Parameters:\n",
    "    model (keras.model): Compiled Model with Weights Loaded\n",
    "    image: Image to Perform Inference On\n",
    "    plot_results (boolean): True - Function Plots using PLT\n",
    "                            False - Returns Heatmap Array\n",
    "    Returns:\n",
    "    Heatmap Array?\n",
    "    \"\"\"\n",
    "    #sanity check\n",
    "    assert (interpolant > 0 and interpolant < 1), \"Heatmap Interpolation Must Be Between 0 - 1\"\n",
    "\n",
    "    #STEP 1: Preprocesss image and make prediction using our model\n",
    "    #input image\n",
    "    original_img = np.asarray(image, dtype = np.float32)\n",
    "    #expamd dimension and get batch size\n",
    "    img = np.expand_dims(original_img, axis=0)\n",
    "    #predict\n",
    "    prediction = model.predict(img)\n",
    "    #prediction index\n",
    "    prediction_idx = np.argmax(prediction)\n",
    "\n",
    "    #STEP 2: Create new model\n",
    "    #specify last convolutional layer\n",
    "    last_conv_layer = next(x for x in model.layers[::-1] if isinstance(x, K.layers.Conv2D))\n",
    "    target_layer = model.get_layer(last_conv_layer.name)\n",
    "\n",
    "    #compute gradient of top predicted class\n",
    "    with tf.GradientTape() as tape:\n",
    "        #create a model with original model inputs and the last conv_layer as the output\n",
    "        gradient_model = Model([model.inputs], [target_layer.output, model.output])\n",
    "        #pass the image through the base model and get the feature map  \n",
    "        conv2d_out, prediction = gradient_model(img)\n",
    "        #prediction loss\n",
    "        loss = prediction[:, prediction_idx]\n",
    "\n",
    "    #gradient() computes the gradient using operations recorded in context of this tape\n",
    "    gradients = tape.gradient(loss, conv2d_out)\n",
    "\n",
    "    #obtain the output from shape [1 x H x W x CHANNEL] -> [H x W x CHANNEL]\n",
    "    output = conv2d_out[0]\n",
    "\n",
    "    #obtain depthwise mean\n",
    "    weights = tf.reduce_mean(gradients[0], axis=(0, 1))\n",
    "\n",
    "\n",
    "    #create a 7x7 map for aggregation\n",
    "    activation_map = np.zeros(output.shape[0:2], dtype=np.float32)\n",
    "    #multiply weight for every layer\n",
    "    for idx, weight in enumerate(weights):\n",
    "        activation_map += weight * output[:, :, idx]\n",
    "    #resize to image size\n",
    "    activation_map = cv2.resize(activation_map.numpy(), \n",
    "                                (original_img.shape[1], \n",
    "                                 original_img.shape[0]))\n",
    "    #ensure no negative number\n",
    "    activation_map = np.maximum(activation_map, 0)\n",
    "    #convert class activation map to 0 - 255\n",
    "    activation_map = (activation_map - activation_map.min()) / (activation_map.max() - activation_map.min())\n",
    "    #rescale and convert the type to int\n",
    "    activation_map = np.uint8(255 * activation_map)\n",
    "\n",
    "\n",
    "    #convert to heatmap\n",
    "    heatmap = cv2.applyColorMap(activation_map, cv2.COLORMAP_JET)\n",
    "\n",
    "    #superimpose heatmap onto image\n",
    "    original_img = np.uint8((original_img - original_img.min()) / (original_img.max() - original_img.min()) * 255)\n",
    "    cvt_heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    cvt_heatmap = img_to_array(cvt_heatmap)\n",
    "\n",
    "    #enlarge plot\n",
    "    plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "    if plot_results == True:\n",
    "        plt.imshow(np.uint8(original_img * interpolant + cvt_heatmap * (1 - interpolant)))\n",
    "    else:\n",
    "        return cvt_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc6153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read an image\n",
    "img = cv2.imread('test_gradcam/Picture9.png')\n",
    "width = 224\n",
    "height = 224\n",
    "dim = (width, height)\n",
    "\n",
    "\n",
    "resized_img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bced044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply function\n",
    "VizGradCAM(reconstructed_model, img_to_array(resized_img), plot_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e7c600",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
